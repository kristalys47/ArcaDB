docker run -dit --mount type=bind,source="$(pwd)",target="/JavaCode" --name rw2 ghcr.io/graalvm/graalvm-ce:latest bash

install https://github.com/oracle/graal.git
git clone https://github.com/oracle/graal.git

docker run -dit --mount type=bind,source="$(pwd)",target="/JavaCode" --name "$(NAME)" ubuntu

apt update -y
apt install -y maven \
openjdk-13 \
git

docker build -f /path/to/a/Dockerfile .
docker build . -t [tag of the image that is forming by the build]

RUN mvn exec:java -Dexec.mainClass="orc.main"


docker compose up
docker stack deploy --compose-file docker-compose.yml [name of services]
docker stack rm [name of services]

docker swarm join-token worker
docker swarm join-token manager



mvn clean install compile package
//// java -cp target/testORC-1.0.jar orc.main "hello" <- deprecated jeje




java -cp target/testORC-1.0.jar orc.main "insert" "/JavaCode/testORC/testFile.orc" "struct<name:string,val:int>" "{\"values\":[[\"kris\",\"4\"],[\"hel\",\"3\"],[\"bye\",\"10\"]]}"



"select * from mytable where mytable.id > 20;"
"struct<id:int,name:string,email:string,address:string>"



How to add credentials so i dont have to ssh with password
http://www.linuxproblem.org/art_9.html


TODO:
-create dockerfile with dependencies to run the project
-Create organized maven project
-shards     // 100 MBytes
-add limits to batch
-Integrate GraaValVM



Docker Commands to create the cluster
docker network create -d bridge dbms  <-- instead of bridge it would be "overlay" if the network is shared in nodes

docker volume create --name comvol


mvn clean install

docker run -[d]it --name ss maven bash
docker cp Distributed-DBMS/ [NAME OF CONTAINER]:/
docker network connect --alias {alias of container} [name of connection] {NAME OF CONTAINER}
docker start -ai ss bash
mvn clean install


mvn exec:java -Dexec.mainClass="orc.main"

docker run --name c3 -p 7271:7271 -it maven bash
jdbc:postgresql://postgresql:5432/postgres

docker run --name postgresql -e POSTGRES_USER=myusername -e POSTGRES_DB=test -e POSTGRES_PASSWORD=mypassword -p 5433:5432 -d postgres

docker pull apacheignite/ignite
docker run -d -p 10800:10800 apacheignite/ignite

SWARMPIT -- tracker
docker run -it --rm \
  --name swarmpit-installer \
  --volume /var/run/docker.sock:/var/run/docker.sock \
swarmpit/install:1.9




java -jar test-ORC.jar


docker network create -d bridge nettest

        Server
        docker run -itd --name test openjdk
        docker network connect --alias server nettest test
        docker cp Main.java test:/
        docker exec -it test bash
        javac Main.Class
        java Main

        Client
        docker run -itd --name test2 openjdk
        docker network connect --alias client nettest test2
        docker cp Main.java test2:/
        docker exec -it test2 bash
        javac Main.Class
        java Main


apt-get install redis-tools

String args = obj.toString();
out.write(args.getBytes(StandardCharsets.UTF_8));
out.flush();

String received = "";
byte[] response;
response = in.readAllBytes();
received = new String(response);


Links that are important

https://generatedata.com
https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-20-04

https://www.tecmint.com/install-nfs-server-on-ubuntu/

https://stackoverflow.com/questions/50042225/how-do-i-combine-or-merge-small-orc-files-into-larger-orc-file
https://programmerall.com/article/62732193206/


docker build . -f DockerfileCoordinator -t coordinator
docker build . -f DockerfileWorker -t worker

http://<host>:7271/database/query
{
    "query": "select * from product inner join customer using(id);",
    "mode": 1,
    "query1": "select * from customer inner join product using(id) where price>500 or price<12;"
}
docker run -d -p 10800:10800 --name ignite apacheignite/ignite
docker run -d -p 10800:10800 --name ignite --network cloud --network-alias postgresql apacheignite/ignite


sudo -E docker stack deploy

env $(cat .env | grep ^[A-Z] | xargs) docker stack deploy --compose-file docker-compose.yml testing


docker run -d -p 5432:5432 --name postgres --network cloud --network-alias postgresql -e POSTGRES_USER=myusername -e POSTGRES_DB=test -e POSTGRES_PASSWORD=mypassword postgres
docker run -d -p 6379:6379 --name redis --network cloud --network-alias redis redis
docker run -d -p 6379:6379 --name redis redis redis-server --save 60 1 --loglevel warning

#  redis:
#    image: redis:latest
#    container_name: redis
#    ports:
#      - target: 6379
#        published: 6379
#        protocol: tcp
#        mode: host
#    networks:
#      cloud:
#        aliases:
#          - redis
#  postgresql:
#    image: postgres
#    container_name: postgres
#    environment:
#      - POSTGRES_USER=myusername
#      - POSTGRES_DB=test
#      - POSTGRES_PASSWORD=mypassword
#    ports:
#      - target: 5432
#        published: 5434
#        protocol: tcp
#        mode: host
#    networks:
#      cloud:
#        aliases:
#          - postgresql

docker compose convert


${S3_BUCKET} ${AWS_S3_ACCESS_KEY} ${AWS_S3_SECRET_KEY} ${REDIS_HOST} ${REDIS_PORT} ${REDIS_HOST_TIMES} ${REDIS_PORT_TIMES} ${WORKER_APP_PORT} ${COORDINATOR_APP_PORT} ${POSTGRES_PASSWORD} ${POSTGRES_USERNAME} ${POSTGRES_HOST} ${POSTGRES_PORT} ${POSTGRES_DB_NAME} ${MODE}

env $(cat .env | grep ^[A-Z] | xargs) docker stack deploy --compose-file docker-compose.yml [STACK_NAME]

docker stack deploy -c <(docker-compose config) stack-name-here
docker stack deploy -c <(docker-compose -f CUSTOM-COMPOSE-FILENAME.yml config) CUSTOM-STACK


set
unset
source
grep -o ^[A-Z1-9_]*


things to load:

1. Containers that are needed;

docker run -d -p 5434:5432 -e POSTGRES_USER=myusername -e POSTGRES_DB=test -e POSTGRES_PASSWORD=mypassword --name postgres postgres
docker run -d -p 6379:6379 --name redis redis
docker run -d -p 6380:6379 --name redis_results redis
docker run -d -p 6379:6379 --name redis redis redis-server --save 60 1 --loglevel warning
 docker run -p 6380:6379 -e REDIS_AOF_ENABLED=no -e REDIS_IO_THREADS=4 -e REDIS_IO_THREADS_DO_READS=true --name redis redis

 Redis config:
 slaveof no one
 CONFIG SET replica-read-only no



2. Change the env.

3. dont forget to change the commands to start in the compose file in acordance with what you want (queue, sockets)


TODO: remake the docker image
TODO: add python to the image intallation

if the project is not being recognize you need to invalidate the caches.

docker run -d --rm --net=host --name alluxios-master -e ALLUXIO_JAVA_OPTS="-DAlluxio.master.hostname=localhost" alluxio/alluxio-enterprise master

docker run -d --rm --net=host --name=alluxio-worker --shm-size=60G -e ALLUXIO_JAVA_OPTS="-Dalluxio.worker.ramdisk.size=60G -Dalluxio.master.hostname=136.145.77.83" alluxio/alluxio-enterprise worker


curl -O https://downloads.alluxio.io/downloads/files/2.8.1/alluxio-2.8.1-bin.tar.gz
tar -xvzpf alluxio-2.8.1-bin.tar.gz

scp root@136.145.77.80:/root/logs.logs logs.log

dos2unix rename.sh
bash rename.sh





MTU

You have to remove the network with the MTU and recreate it with the correct MTU
docker network rm docker_gwbridge
docker network create -d bridge --subnet 172.18.0.0/16 --opt com.docker.network.bridge.name=docker_gwbridge --opt com.docker.network.bridge.enable_icc=false --opt com.docker.network.bridge.enable_ip_masquerade=true --opt com.docker.network.driver.mtu=1442 docker_gwbridge





scp root@136.145.77.83:/root/spark-3.3.1/conf/* .


scp . root@136.145.77.94:/root/spark-3.3.1/conf/

rpush python "{\"plan\": [\"udf\", \"/image\", \"imageClassifier\", \"gender\", \"true\"]}"


RUN apt install -y python3-opencv

apt install -y python3-opencv


set -a # automatically export all variables
source .env
set +a

export $(xargs <.env)
docker run --rm -it kristalys/dbms-coordinator-calcite:0.8 mvn exec:java -Dexec.mainClass="coordinator.Coordinator" -Dexec.args="${S3_BUCKET} ${AWS_S3_ACCESS_KEY} ${AWS_S3_SECRET_KEY} ${REDIS_HOST} ${REDIS_PORT} ${REDIS_HOST_TIMES} ${REDIS_PORT_TIMES} ${WORKER_APP_PORT} ${COORDINATOR_APP_PORT} ${POSTGRES_PASSWORD} ${POSTGRES_USERNAME} ${POSTGRES_HOST} ${POSTGRES_PORT} ${POSTGRES_DB_NAME} ${MODE}" -Dexec.cleanupDaemonThreads=false -Dsbt.classloader.close=false

env $(cat .env | xargs) rails
env $(cat .env | grep ^[A-Z] | xargs)
env $(cat .env | grep ^[A-Z] | xargs) docker stack deploy --compose-file docker-compose.yml testing
