{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First setup the dictionaries to mapp from chars to positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', ';', '.', '!', '?', ':', \"'\", '\"', '/', '\\\\', '|', '_', '@', '#', '$', '%', '^', '&', '*', '~', '`', '+', '-', '=', '<', '>', '(', ')', '[', ']', '{', '}']\n",
      "94\n",
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'a': 26, 'b': 27, 'c': 28, 'd': 29, 'e': 30, 'f': 31, 'g': 32, 'h': 33, 'i': 34, 'j': 35, 'k': 36, 'l': 37, 'm': 38, 'n': 39, 'o': 40, 'p': 41, 'q': 42, 'r': 43, 's': 44, 't': 45, 'u': 46, 'v': 47, 'w': 48, 'x': 49, 'y': 50, 'z': 51, '0': 52, '1': 53, '2': 54, '3': 55, '4': 56, '5': 57, '6': 58, '7': 59, '8': 60, '9': 61, ',': 62, ';': 63, '.': 64, '!': 65, '?': 66, ':': 67, \"'\": 68, '\"': 69, '/': 70, '\\\\': 71, '|': 72, '_': 73, '@': 74, '#': 75, '$': 76, '%': 77, '^': 78, '&': 79, '*': 80, '~': 81, '`': 82, '+': 83, '-': 84, '=': 85, '<': 86, '>': 87, '(': 88, ')': 89, '[': 90, ']': 91, '{': 92, '}': 93}\n",
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'a', 27: 'b', 28: 'c', 29: 'd', 30: 'e', 31: 'f', 32: 'g', 33: 'h', 34: 'i', 35: 'j', 36: 'k', 37: 'l', 38: 'm', 39: 'n', 40: 'o', 41: 'p', 42: 'q', 43: 'r', 44: 's', 45: 't', 46: 'u', 47: 'v', 48: 'w', 49: 'x', 50: 'y', 51: 'z', 52: '0', 53: '1', 54: '2', 55: '3', 56: '4', 57: '5', 58: '6', 59: '7', 60: '8', 61: '9', 62: ',', 63: ';', 64: '.', 65: '!', 66: '?', 67: ':', 68: \"'\", 69: '\"', 70: '/', 71: '\\\\', 72: '|', 73: '_', 74: '@', 75: '#', 76: '$', 77: '%', 78: '^', 79: '&', 80: '*', 81: '~', 82: '`', 83: '+', 84: '-', 85: '=', 86: '<', 87: '>', 88: '(', 89: ')', 90: '[', 91: ']', 92: '{', 93: '}'}\n"
     ]
    }
   ],
   "source": [
    "characters = list(\"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "print(characters)\n",
    "print(len(characters))\n",
    "character_to_integer = dict((c, i) for i, c in enumerate(characters))\n",
    "integer_to_character = dict((i, c) for i, c in enumerate(characters))\n",
    "print(character_to_integer)\n",
    "print(integer_to_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us no look at how a SMILE string gets mapped to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 54, 7, 91, 2, 53, 85, 2, 88, 2, 88, 85, 2, 88, 2, 88, 85, 2, 53, 13, 2, 88, 85, 14, 89, 2, 89, 90, 54, 7, 91, 89, 90, 54, 7, 91, 89, 14, 89, 90, 54, 7, 91]\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "test_str = \"[2H]C1=C(C(=C(C(=C1NC(=O)C)[2H])[2H])O)[2H]\"\n",
    "integer_encoded = [character_to_integer[char] for char in test_str]\n",
    "print(integer_encoded)\n",
    "print(len(integer_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a one-hot encoding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(target, character_set_len:int):\n",
    "    one_hot = list()\n",
    "    for value in target:\n",
    "        #first make everything a 0\n",
    "        L = [0 for _ in range(character_set_len)]\n",
    "        # now add one at the position of this character\n",
    "        L[value] = 1\n",
    "        one_hot.append(L)\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]\n",
      "43\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "one_hot=one_hot_encode(integer_encoded,len(characters))\n",
    "print(one_hot)\n",
    "print(len(one_hot)) #43 one-hot vectors of size 94\n",
    "print(len(one_hot[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set from the smiles data. The data has 1,129,199 rows. The smiles data has string with average size of 56, max size of 1329. But there are 1,061,957 row with size less than 100. So, we will use that becuase it is 94% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SMILESDataSet(Dataset):\n",
    "    def __init__(self, smiles_file, train=True, max_str_len = 100, transform=None, target_transform=None):\n",
    "        super(SMILESDataSet, self).__init__()\n",
    "        self.smiles_file = smiles_file\n",
    "        self.max_str_len = max_str_len\n",
    "        if(train == True):\n",
    "            self.size = 200000\n",
    "        else:\n",
    "            self.size = 50000\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        #character set\n",
    "        self.characters = list(\"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "        self.character_to_integer = dict((c, i) for i, c in enumerate(characters))\n",
    "        self.integer_to_character = dict((i, c) for i, c in enumerate(characters))\n",
    "        \n",
    "        #open csv\n",
    "        self.smiles_csv = pd.read_csv(smiles_file)\n",
    "        #filter out those lines with canonical smiles string longer than 100\n",
    "        self.smiles_csv = self.smiles_csv[self.smiles_csv.apply(lambda x: len(x['CanonicalSMILES']) <= 100, axis=1)]\n",
    "        #sample data based on size\n",
    "        self.smiles_data =  self.smiles_csv.sample(n=self.size).reset_index()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #print(\"Index: \", idx)\n",
    "        #print(\"Row: \\n\", self.smiles_data.iloc[idx])\n",
    "        X = self.smiles_data.iloc[idx, 3] # Canonical smiles\n",
    "        #print(\"X: \", X)\n",
    "        y = self.smiles_data.iloc[idx, 5] # molecular weight\n",
    "        #print(\"y: \", y)\n",
    "        label = torch.tensor(y, dtype=torch.float32)\n",
    "        #label = torch.FloatTensor(y)\n",
    "        data = self.one_hot_encode(X, len(self.characters))\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        #data = torch.FloatTensor(data)\n",
    "        #print(\"data.shape: \", data.shape)\n",
    "        data = data.transpose(0, 1)\n",
    "        return data, label\n",
    "    \n",
    "    def one_hot_encode(self, target, character_set_len:int):\n",
    "        integer_encoded = [self.character_to_integer[char] for char in target]\n",
    "        one_hot = list()\n",
    "        for value in integer_encoded:\n",
    "            #first make everything a 0\n",
    "            L = [0 for _ in range(character_set_len)]\n",
    "            # now add one at the position of this character\n",
    "            L[value] = 1\n",
    "            one_hot.append(L)\n",
    "        one_hot = self.zero_pad(one_hot, self.max_str_len, character_set_len)\n",
    "        return one_hot\n",
    "    \n",
    "    def zero_pad(self, one_hot, max_str_len, character_set_len):\n",
    "        L = [0 for _ in range(character_set_len)]\n",
    "        while (len(one_hot) < max_str_len):\n",
    "            one_hot.append(L)\n",
    "        return one_hot\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set and training set and setup their data loaders\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data len:  200000\n",
      "test data len:  50000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "smiles_file = \"./master_corpus2.csv\"\n",
    "training_data = SMILESDataSet(smiles_file, train=True)\n",
    "print(\"training data len: \", training_data.__len__())\n",
    "test_data = SMILESDataSet(smiles_file, train=False)\n",
    "print(\"test data len: \", test_data.__len__())\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see a few items from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape torch.Size([64, 94, 100])\n",
      "train_labels.shape torch.Size([64])\n",
      "len(C):  94\n",
      "train features[0] tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "train labels[0[]] tensor(465.5000)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(\"train_features.shape\", train_features.shape)\n",
    "print(\"train_labels.shape\", train_labels.shape)\n",
    "C = list(\"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "print(\"len(C): \" , len(C))\n",
    "print(\"train features[0]\", train_features[0] )\n",
    "print(\"train labels[0[]]\", train_labels[0] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the create then NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features,shape:  torch.Size([64, 94, 100])\n",
      "out.shape:  torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CharacterLevelCNN(nn.Module):\n",
    "    def __init__(self, input_length, input_dim, n_conv_filters, n_fc_neurons=128, kernel_size=7, padding=0):\n",
    "        super(CharacterLevelCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size, stride=1, padding=padding), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3)) \n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size, stride=1, padding=padding), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.conv5 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(nn.Linear(input_length, n_fc_neurons), nn.ReLU(), nn.Dropout(0.2))  \n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, 64), nn.ReLU(),nn.Dropout(0.2))  \n",
    "        self.fc3 = nn.Sequential(nn.Linear(64, 32), nn.ReLU(),nn.Dropout(0.2))  \n",
    "        self.fc4 = nn.Sequential(nn.Linear(32, 1))   \n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.conv1(X)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        output = self.conv5(output)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc3(output)\n",
    "        output = self.fc4(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model =  CharacterLevelCNN(128, 94, 64)\n",
    "print(\"train_features,shape: \", train_features.shape)\n",
    "out = model(train_features)  \n",
    "#M = out.view(10, -1)\n",
    "print(\"out.shape: \", out.shape)     \n",
    "#print(\"M.shape: \", M.shape)     \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelrodriguez/miniconda3/envs/pytorch2/lib/python3.8/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/Users/manuelrodriguez/miniconda3/envs/pytorch2/lib/python3.8/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "CharacterLevelCNN                        [64, 94, 100]             [64, 1]                   --\n",
       "├─Sequential: 1-1                        [64, 94, 100]             [64, 64, 31]              --\n",
       "│    └─Conv1d: 2-1                       [64, 94, 100]             [64, 64, 94]              42,176\n",
       "│    └─ReLU: 2-2                         [64, 64, 94]              [64, 64, 94]              --\n",
       "│    └─MaxPool1d: 2-3                    [64, 64, 94]              [64, 64, 31]              --\n",
       "├─Sequential: 1-2                        [64, 64, 31]              [64, 64, 8]               --\n",
       "│    └─Conv1d: 2-4                       [64, 64, 31]              [64, 64, 25]              28,736\n",
       "│    └─ReLU: 2-5                         [64, 64, 25]              [64, 64, 25]              --\n",
       "│    └─MaxPool1d: 2-6                    [64, 64, 25]              [64, 64, 8]               --\n",
       "├─Sequential: 1-3                        [64, 64, 8]               [64, 64, 6]               --\n",
       "│    └─Conv1d: 2-7                       [64, 64, 8]               [64, 64, 6]               12,352\n",
       "│    └─ReLU: 2-8                         [64, 64, 6]               [64, 64, 6]               --\n",
       "├─Sequential: 1-4                        [64, 64, 6]               [64, 64, 4]               --\n",
       "│    └─Conv1d: 2-9                       [64, 64, 6]               [64, 64, 4]               12,352\n",
       "│    └─ReLU: 2-10                        [64, 64, 4]               [64, 64, 4]               --\n",
       "├─Sequential: 1-5                        [64, 64, 4]               [64, 64, 2]               --\n",
       "│    └─Conv1d: 2-11                      [64, 64, 4]               [64, 64, 2]               12,352\n",
       "│    └─ReLU: 2-12                        [64, 64, 2]               [64, 64, 2]               --\n",
       "├─Sequential: 1-6                        [64, 128]                 [64, 128]                 --\n",
       "│    └─Linear: 2-13                      [64, 128]                 [64, 128]                 16,512\n",
       "│    └─ReLU: 2-14                        [64, 128]                 [64, 128]                 --\n",
       "│    └─Dropout: 2-15                     [64, 128]                 [64, 128]                 --\n",
       "├─Sequential: 1-7                        [64, 128]                 [64, 64]                  --\n",
       "│    └─Linear: 2-16                      [64, 128]                 [64, 64]                  8,256\n",
       "│    └─ReLU: 2-17                        [64, 64]                  [64, 64]                  --\n",
       "│    └─Dropout: 2-18                     [64, 64]                  [64, 64]                  --\n",
       "├─Sequential: 1-8                        [64, 64]                  [64, 32]                  --\n",
       "│    └─Linear: 2-19                      [64, 64]                  [64, 32]                  2,080\n",
       "│    └─ReLU: 2-20                        [64, 32]                  [64, 32]                  --\n",
       "│    └─Dropout: 2-21                     [64, 32]                  [64, 32]                  --\n",
       "├─Sequential: 1-9                        [64, 32]                  [64, 1]                   --\n",
       "│    └─Linear: 2-22                      [64, 32]                  [64, 1]                   33\n",
       "===================================================================================================================\n",
       "Total params: 134,849\n",
       "Trainable params: 134,849\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 310.92\n",
       "===================================================================================================================\n",
       "Input size (MB): 2.41\n",
       "Forward/backward pass size (MB): 4.41\n",
       "Params size (MB): 0.54\n",
       "Estimated Total Size (MB): 7.35\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=train_features.shape, device='cpu', col_names=['input_size', 'output_size',\n",
    "                                                                               'num_params'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data set and data loader for returning the strings encoded as integers. Embedding layer will take care of conversions to dense vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SMILESEmbedDataSet(Dataset):\n",
    "    def __init__(self, smiles_file, train=True, max_str_len = 100, transform=None, target_transform=None):\n",
    "        super(SMILESEmbedDataSet, self).__init__()\n",
    "        self.smiles_file = smiles_file\n",
    "        self.max_str_len = max_str_len\n",
    "        if(train == True):\n",
    "            self.size = 200000\n",
    "        else:\n",
    "            self.size = 50000\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        #character set\n",
    "        self.characters = list(\"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "        self.character_to_integer = dict((c, i) for i, c in enumerate(characters))\n",
    "        self.integer_to_character = dict((i, c) for i, c in enumerate(characters))\n",
    "         #open csv\n",
    "        self.smiles_csv = pd.read_csv(smiles_file)\n",
    "        #filter out those lines with canonical smiles string longer than 100\n",
    "        self.smiles_csv = self.smiles_csv[self.smiles_csv.apply(lambda x: len(x['CanonicalSMILES']) <= 100, axis=1)]\n",
    "        #sample data based on size\n",
    "        self.smiles_data =  self.smiles_csv.sample(n=self.size).reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #print(\"Index: \", idx)\n",
    "        #print(\"Row: \\n\", self.smiles_data.iloc[idx])\n",
    "        X = self.smiles_data.iloc[idx, 3] # Canonical smiles\n",
    "        #print(\"X: \", X)\n",
    "        y = self.smiles_data.iloc[idx, 5] # molecular weight\n",
    "        #print(\"y: \", y)\n",
    "        label = torch.tensor(y, dtype=torch.float32)\n",
    "        #label = torch.FloatTensor(y)\n",
    "        data = self.integer_encode(X)\n",
    "        data = self.pad(data, self.max_str_len, len(self.characters))\n",
    "        data = torch.tensor(data, dtype=torch.int32)\n",
    "        #data = torch.FloatTensor(data)\n",
    "        #print(\"data.shape: \", data.shape)\n",
    "        #data = data.transpose(0, 1)\n",
    "        return data, label\n",
    "    \n",
    "    def integer_encode(self, target):\n",
    "        integer_encoded = [self.character_to_integer[char] for char in target]\n",
    "        return integer_encoded\n",
    "    \n",
    "    def pad(self, target, max_str_len, max_vocab_len):\n",
    "        # pad with integer position max_vocab_len until we reach max_str_len\n",
    "        while len(target) < max_str_len:\n",
    "            target.append(max_vocab_len)\n",
    "        return target\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup cost criterion and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data len:  200000\n",
      "test data len:  50000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "smiles_file = \"./master_corpus2.csv\"\n",
    "training_data = SMILESEmbedDataSet(smiles_file, train=True)\n",
    "print(\"training data len: \", training_data.__len__())\n",
    "test_data = SMILESEmbedDataSet(smiles_file, train=False)\n",
    "print(\"test data len: \", test_data.__len__())\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features.shape torch.Size([64, 100])\n",
      "train_labels.shape torch.Size([64])\n",
      "len(C):  94\n",
      "train features[0] tensor([ 2, 53, 85,  2,  2, 85,  2, 54,  2, 88, 85,  2, 53, 89,  2, 55, 85,  2,\n",
      "        88, 13, 54, 89,  2, 88, 85, 14, 89, 13, 88, 13, 85,  2, 55, 89,  2,  2,\n",
      "        88, 85, 14, 89, 13,  2, 56, 85,  2,  2, 85,  2,  2, 88, 85,  2, 56, 89,\n",
      "         2, 88,  5, 89, 88,  5, 89,  5, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94,\n",
      "        94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94,\n",
      "        94, 94, 94, 94, 94, 94, 94, 94, 94, 94], dtype=torch.int32)\n",
      "train labels[0[]] tensor(386.3000)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(\"train_features.shape\", train_features.shape)\n",
    "print(\"train_labels.shape\", train_labels.shape)\n",
    "C = list(\"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\"\")\n",
    "print(\"len(C): \" , len(C))\n",
    "print(\"train features[0]\", train_features[0] )\n",
    "print(\"train labels[0]\", train_labels[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NN with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CharacterLevelCNNEmbed(nn.Module):\n",
    "    def __init__(self, vocab_len, input_length, input_dim, n_conv_filters, n_fc_neurons=128, kernel_size=7, padding=0):\n",
    "        super(CharacterLevelCNNEmbed, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab_len), embedding_dim=input_dim)\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(input_dim, n_conv_filters, kernel_size, stride=1, padding=padding), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3)) \n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size, stride=1, padding=padding), nn.ReLU(),\n",
    "                                   nn.MaxPool1d(3))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.conv5 = nn.Sequential(nn.Conv1d(n_conv_filters, n_conv_filters, kernel_size=3, stride=1, padding=padding), nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(nn.Linear(input_length, n_fc_neurons), nn.ReLU(), nn.Dropout(0.2))  \n",
    "        self.fc2 = nn.Sequential(nn.Linear(n_fc_neurons, 64), nn.ReLU(),nn.Dropout(0.2))  \n",
    "        self.fc3 = nn.Sequential(nn.Linear(64, 32), nn.ReLU(),nn.Dropout(0.2))  \n",
    "        self.fc4 = nn.Sequential(nn.Linear(32, 1))   \n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.conv1(X)\n",
    "        output = self.conv2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        output = self.conv5(output)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc3(output)\n",
    "        output = self.fc4(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model =  CharacterLevelCNN(128, 94, 64)\n",
    "print(\"train_features,shape: \", train_features.shape)\n",
    "out = model(train_features)  \n",
    "#M = out.view(10, -1)\n",
    "print(\"out.shape: \", out.shape)     \n",
    "#print(\"M.shape: \", M.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrat to keep loss after each iteration\n",
    "loss_list = []\n",
    "# number of iterations\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 1000 loss: 11536.044882080078\n",
      "  batch 2000 loss: 4944.318415283203\n",
      "  batch 3000 loss: 4841.683582641602\n",
      "  batch 1000 loss: 4586.1502570800785\n",
      "  batch 2000 loss: 4695.881820922851\n",
      "  batch 3000 loss: 4436.855819702148\n",
      "  batch 1000 loss: 4481.561770629883\n",
      "  batch 2000 loss: 4396.334609619141\n",
      "  batch 3000 loss: 4489.080185546875\n",
      "  batch 1000 loss: 4427.607578735351\n",
      "  batch 2000 loss: 4466.677286865234\n",
      "  batch 3000 loss: 4377.355996948242\n",
      "  batch 1000 loss: 4298.894345458984\n",
      "  batch 2000 loss: 4242.737025878906\n",
      "  batch 3000 loss: 4245.360828857421\n",
      "  batch 1000 loss: 4242.1886917724605\n",
      "  batch 2000 loss: 4129.0558395996095\n",
      "  batch 3000 loss: 4209.996467773438\n",
      "  batch 1000 loss: 4148.444652954102\n",
      "  batch 2000 loss: 4022.795212524414\n",
      "  batch 3000 loss: 4121.693369018555\n",
      "  batch 1000 loss: 4070.5292716064455\n",
      "  batch 2000 loss: 3980.682705078125\n",
      "  batch 3000 loss: 3950.0132735595703\n",
      "  batch 1000 loss: 3872.313399291992\n",
      "  batch 2000 loss: 3870.9380885009764\n",
      "  batch 3000 loss: 3821.212956176758\n",
      "  batch 1000 loss: 3686.363540771484\n",
      "  batch 2000 loss: 3678.5859301757814\n",
      "  batch 3000 loss: 3603.3923017578127\n",
      "  batch 1000 loss: 3535.4566767578126\n",
      "  batch 2000 loss: 3406.323998535156\n",
      "  batch 3000 loss: 3493.6581492919922\n",
      "  batch 1000 loss: 3362.4168283691406\n",
      "  batch 2000 loss: 3312.7795087890627\n",
      "  batch 3000 loss: 3291.386706665039\n",
      "  batch 1000 loss: 3250.125757446289\n",
      "  batch 2000 loss: 3174.6141849365235\n",
      "  batch 3000 loss: 3264.5683896484375\n",
      "  batch 1000 loss: 3152.3163907470703\n",
      "  batch 2000 loss: 3094.7226595458983\n",
      "  batch 3000 loss: 3105.1161481933595\n",
      "  batch 1000 loss: 3139.1006364746095\n",
      "  batch 2000 loss: 3110.5914809570313\n",
      "  batch 3000 loss: 3067.8781655273438\n",
      "  batch 1000 loss: 3024.135668334961\n",
      "  batch 2000 loss: 3029.9476668701172\n",
      "  batch 3000 loss: 2974.321009033203\n",
      "  batch 1000 loss: 2958.9779462890624\n",
      "  batch 2000 loss: 2953.208377685547\n",
      "  batch 3000 loss: 2903.5831931152343\n",
      "  batch 1000 loss: 2901.4181256103516\n",
      "  batch 2000 loss: 2830.3708170166014\n",
      "  batch 3000 loss: 2866.8448564453124\n",
      "  batch 1000 loss: 2774.851469543457\n",
      "  batch 2000 loss: 2800.0228586425783\n",
      "  batch 3000 loss: 2757.373776611328\n",
      "  batch 1000 loss: 2773.280382324219\n",
      "  batch 2000 loss: 2751.200378051758\n",
      "  batch 3000 loss: 2704.8559739990233\n"
     ]
    }
   ],
   "source": [
    "for e  in range(epochs):\n",
    "    running_loss = 0.\n",
    "    last_lost = 0.\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        X, Y = data\n",
    "        #setup optimizer to zero grandients\n",
    "        optimizer.zero_grad()\n",
    "        # Make predictions for the all the examples in X (vectorization)\n",
    "        Y_pred = model.forward(X)\n",
    "        # now calculate the loss \n",
    "        Y = Y.unsqueeze(1)\n",
    "        loss = criterion(Y_pred, Y)\n",
    "        #append the lost to the list\n",
    "        #loss_list.append(loss.item())\n",
    "        #back propagation step\n",
    "        loss.backward()\n",
    "        #parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            loss_list.append(last_loss)\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            #tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    # print diagnostic data\n",
    "    #print('{}, \\t{}, \\t{}'.format(i, loss.item(), [param.data for param in model.parameters()]))\n",
    "\n",
    "    #with torch.no_grad():\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list, 'r')\n",
    "plt.tight_layout()\n",
    "plt.grid('True', color='y')\n",
    "plt.xlabel(\"Epochs/Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './mymodelemb.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
